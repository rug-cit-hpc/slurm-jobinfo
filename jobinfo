#!/usr/bin/python2
# -*- coding: utf-8 -*-
#
# jobinfo - collect job information from slurm in nicely readable format
#
# Copyright 2015 Anders Halager <aeh@birc.au.dk>
# More functionality added by Bob Dr√∂ge <b.e.droge@rug.nl>
# and Egon Rijpkema <e.m.a.rijpkema@rug.nl>
#
# LICENSE: MIT

from __future__ import print_function
from __future__ import division
from collections import namedtuple as NT
import datetime
import json
import math
import os
import pwd
import re
import requests
import subprocess
import sys
import time

# pynumparser should have been installed to /usr/lib.
# However, if another Python version is loaded as module,
# Python may fail to find pynumparser. In this case we add it
# to the search path manually and try again.
try:
    import pynumparser
except ImportError:
    sys.path.append('/usr/lib/python2.7/site-packages/')
    import pynumparser

def append(l, x):
    if l == '':
        return x
    return ','.join(sorted(set(l.split(',') + [x])))


def keep_first(a, b):
    return a == '' and b or a


def time_max(a, b):
    if 'UNLIMITED' in [a, b]:
        return 'UNLIMITED'
    if a in ['', 'INVALID']:
        return b
    if b in ['', 'INVALID']:
        return a
    return max(a, b)


def time_min(a, b):
    if a in ['', 'INVALID', 'UNLIMITED']:
        return b
    if b in ['', 'INVALID', 'UNLIMITED']:
        return a
    return max(a, b)


def byte_size(s=None):
    if s is None or s == "16?":
        return 0.0
    m = {'K': 10, 'M': 20, 'G': 30, 'T': 40, 'P': 50, 'E': 60}
    scale = 2**m.get(s[-1], 0)
    if scale != 1:
        s = s[:-1]
    return scale * float(s)


def date_str(s=None):
    if s is None or s.strip() == "":
        return "9999-01-01T00:00:00"
    return s


def format_bs(x):
    postfix = ' KMGTPE'
    e = int(math.log(x + 1, 2) / 10)
    return "%.2f%s" % (x / 2**(10 * e), postfix[e])


# Format: [DD-[hh:]]mm:ss
time_parts = re.compile(r'(((?P<days>\d+)-)?(?P<hours>\d\d):)?' +
                        r'(?P<minutes>\d\d):(?P<seconds>\d\d(\.\d+)?)')


def parse_time(t):
    m = time_parts.match(t)
    if m is None:
        return 0.0, 0, 0, 0
    ss = float(m.group('seconds'))
    mm = int(m.group('minutes'))
    hh = int(m.group('hours') or '0')
    dd = int(m.group('days') or '0')
    return ss, mm, hh, dd


def elapsed_to_seconds(elapsed):
    ss, mm, hh, dd = parse_time(elapsed)
    return dd * 24 * 60 * 60 + hh * 60 * 60 + mm * 60 + ss


def f_rss(x, meta):
    return "%s (%s)" % (format_bs(x), meta.MaxRSSNode)


def f_dw(x, meta):
    return "%s (%s)" % (format_bs(x), meta.MaxDiskWriteNode)


def f_dr(x, meta):
    return "%s (%s)" % (format_bs(x), meta.MaxDiskReadNode)


def f_cpu(x, meta):
    total = elapsed_to_seconds(meta.TotalCPU)
    if total == 0:
        return "--"
    xp = elapsed_to_seconds(x)
    return "%5.2f%%" % (xp / total * 100)


def f_mem(x, meta):
    if x.endswith('c'):
        return "%s/core" % (x[:-1])
    elif x.endswith('n'):
        return "%s/node" % (x[:-1])
    else:
        return x


def f_time(x, meta):
    all_times = [meta.timelimit, meta.elapsed, meta.TotalCPU, '-']
    days_len = max(len(y.split('-')[0]) for y in all_times if '-' in y)
    ss, mm, hh, dd = parse_time(x)
    if days_len == 0:
        dd = ""
    else:
        if dd > 0:
            dd = ("%i-" % dd).rjust(days_len)
        else:
            dd = " " * (days_len + 1)
    res = "%s%02i:%02i:%02i" % (dd, hh, mm, ss)
    if res.strip() == "00:00:00":
        return "--"
    return res


def f_cputime(x, meta):
    res = f_time(x, meta)
    if res != "--":
        res += " (efficiency: %5.2f%%)" % efficiency(meta)
    return res


def f_str(x, meta):
    return str(x)


def f_date(x, meta):
    if str(x).lower() == "unknown":
        return "--"
    return str(x)


def f_state(x, meta):
    states = set(x.split(","))
    if len(states) > 1:
        states = states - set(["COMPLETED", ""])
    reason = meta.reason
    if reason != '':
        reason = ' ' + reason
    deps = meta.dependencies
    if deps != '':
        deps = " (%s)" % deps
    return ','.join(states) + reason + deps


def efficiency(meta):
    cputime_secs = elapsed_to_seconds(meta.TotalCPU)
    walltime_secs = elapsed_to_seconds(meta.elapsed)
    ncpus = meta.ncpus
    if cputime_secs == 0 or walltime_secs == 0 or ncpus == 0:
        eff = 0
    else:
        eff = 100 * elapsed_to_seconds(
            meta.TotalCPU) / (meta.ncpus * elapsed_to_seconds(meta.elapsed))
    return eff


def whoami():
    return pwd.getpwuid(os.getuid()).pw_name


Field = NT('Field', 'name ctor combinator shown prefer_live formatter desc')
FIELDS = [
        Field("JobName",             str,        keep_first,   True,  False, f_str,     "Name"),
        Field("User",                str,        keep_first,   True,  False, f_str,     "User"),
        Field("Partition",           str,        keep_first,   True,  False, f_str,     "Partition"),
        Field("NodeList",            str,        keep_first,   True,  False, f_str,     "Nodes"),
        Field("ncpus",               int,        max,          True,  False, f_str,     "Cores"),
        Field("State",               str,        append,       True,  False, f_state,   "State"),
        Field("Submit",              str,        keep_first,   True,  False, f_str,     "Submit"),
        Field("start",               date_str,   min,          True,  False, f_date,    "Start"),
        Field("end",                 str,        time_max,     True,  False, f_date,    "End"),
        Field("timelimit",           str,        time_max,     True,  False, f_time,    "Reserved walltime"),
        Field("elapsed",             str,        time_max,     True,  False, f_time,    "Used walltime"),
        Field("TotalCPU",            str,        max,          True,  False, f_cputime, "Used CPU time"),
        Field("UserCPU",             str,        max,          True,  False, f_cpu,     "% User (Computation)"),
        Field("SystemCPU",           str,        max,          True,  False, f_cpu,     "% System (I/O)"),
        Field("ReqMem",              str,        keep_first,   True,  False, f_mem,     "Mem reserved"),
        Field("MaxRSS",              byte_size,  max,          True,  True,  f_rss,     "Max Mem used"),
        Field("MaxDiskWrite",        byte_size,  max,          True,  True,  f_dw,      "Max Disk Write"),
        Field("MaxDiskRead",         byte_size,  max,          True,  True,  f_dr,      "Max Disk Read"),

        Field("MaxRSSNode",          str,        append,       False, True,  None,      ""),
        Field("MaxDiskWriteNode",    str,        append,       False, True,  None,      ""),
        Field("MaxDiskReadNode",     str,        append,       False, True,  None,      ""),
        Field("Comment",             str,        keep_first,   False, False, None,      ""),
        ]

FIELD_NAMES = [f.name for f in FIELDS]
FIELD_NAMES_LIVE = [f.name for f in FIELDS if f.prefer_live]
FIELD_CTORS = [f.ctor for f in FIELDS]
FIELD_COMB = [f.combinator for f in FIELDS]
FORMAT_STR = "--format=%s" % (",".join(FIELD_NAMES))
FORMAT_LIVE_STR = "--format=%s" % (",".join(FIELD_NAMES_LIVE))
Meta = NT('Meta', FIELD_NAMES + ['dependencies', 'reason'])


def combine(xs):
    r = xs[0]
    for x in xs[1:]:
        for i, comb in enumerate(FIELD_COMB):
            r[i] = comb(r[i], x[i])
    return r


def get_values(jobid):
    info = subprocess.Popen(
        ['sacct', FORMAT_STR, '--parsable', '--noheader', '-j', jobid],
        stdout=subprocess.PIPE)
    xs = []
    for line in info.stdout:
        xs.append(
            [(s != "" and ctor(s) or ctor())
             for ctor, s in zip(FIELD_CTORS,
                                line.decode('utf-8').strip().split('|'))])
    if len(xs) == 0:
        print("No such job", file=sys.stderr)
        sys.exit(1)
    return xs


def get_live_values(jobid):
    info = subprocess.Popen(
        [
            'sstat', FORMAT_LIVE_STR, '--parsable', '--noheader', '-a', '-j',
            jobid
        ],
        stdout=subprocess.PIPE)
    xs = []
    for line in info.stdout:
        j = 0
        vals = line.decode('utf-8').strip().split('|')
        x = []
        for f in FIELDS:
            if f.prefer_live:
                x.append(f.ctor(vals[j]))
                j += 1
            else:
                x.append(f.ctor())
            xs.append(x)
    return xs


def parse_gpu_string(node_string):
    """
    Parses a string in the format of.
    pg-gpu[1-3] or pg-gpu[2,4,5]
    """
    match = re.search('(.+\[)([0-9]|-|,)+?(?=\])', node_string)
    if match is None:
        return [node_string]

    base, sequence = match.group().split('[')
    parser = pynumparser.NumberSequence(int)
    return ['{}{:02d}'.format(base, i) for i in parser.parse(sequence)]


def get_gpu_usage(node, start, end):
    """
    Calculate the average GPU usage between begin and end stamps.
    Args:
      node (string): The GPU node.
      start (int): start of measurements timestamp.
      end (int): end of measurements timestamp.
    """


    payload = {
        'query':
        'utilization_gpu{{env="peregrine",instance="{}:9101",job="gpu"}}'.
        format(node),
        'start':
        start,
        'end':
        end,
        'step':
        '60s'
    }

    data = requests.get(
        'https://knyft.hpc.rug.nl:9091/api/v1/query_range', params=payload)
    print('https://knyft.hpc.rug.nl:9091/api/v1/query_range', payload)
    values = []

    for gpu in range(len(json.loads(data.content.decode())['data']['result'])):
        values += json.loads(data.content.decode())['data']['result'][gpu]['values']

    average = sum([int(i[1]) for i in values]) / len(values)
    return average


def get_gpus_usage(nodes, start, end):
    """
    Calculate the average GPU usage between begin and end stamps.
    of a sequence of gpus.
    Args:
      nodes (string): The GPU node(s) in slurm format.
      start (int): start of measurements timestamp.
      end (int): end of measurements timestamp.
    Returns: List: A list of tuples [(<hostname>, <percentage>)]
    """
    return [(gpu, get_gpu_usage(gpu, start, end))
            for gpu in parse_gpu_string(nodes)]


def main(jobid):
    y = combine(get_values(jobid))
    meta = Meta._make(y + ['', ''])
    ys = [y]
    if meta.State == "RUNNING" and (os.getuid() == 0 or meta.User == whoami()):
        # get more info from sstat
        tmp = get_live_values("%s,%s.batch" % (jobid, jobid))
        if len(tmp) != 0:
            ys.append(combine(tmp))
    if meta.State == "PENDING":
        info = subprocess.Popen(
            ['squeue', '--format=%E;%R', '--noheader', '-a', '-j', jobid],
            stdout=subprocess.PIPE)
        deps, reason = info.stdout.readline().decode('utf-8').strip().split(
            ";")
        dependencies = deps
    else:
        dependencies = ""
        reason = ""
    y = combine(ys)
    meta = Meta._make(y + [dependencies, reason])

    for i, (name, parse, comb, show, prefer_live, format,
            desc) in enumerate(FIELDS):
        val = y[i]
        if show:
            print("%-20s: %s" % (desc, format(val, meta)))

    # for  gpu jobs, retreive gpu usage from prometheus.
    if y[2] == 'gpu' and y[7] != 'Unknown':
        start = time.mktime(datetime.datetime.strptime(
            y[7], '%Y-%m-%dT%H:%M:%S').timetuple())
        if y[8] == 'Unknown':
            end = time.time()
        else:
            end = time.mktime(datetime.datetime.strptime(
                y[8], '%Y-%m-%dT%H:%M:%S').timetuple())
        # prevent the script from crashing if anything  goes wrong.
        # But we do want to read the exception.
        try:
            gpu_usages = get_gpus_usage(y[3], start, end)
            for gpu, usage in gpu_usages:
                print('%-20s: %.1f%% (%s)' % ('Average GPU usage', usage, gpu))
        except Exception as e:
            if type(e) == IndexError:
                print(
                    '\nError: No GPU metrics available ({})'.format(y[3]),
                    file=sys.stderr)
            else:
                print('\nGPU usage could not be retrieved.',
                      'The error was:\n')
                print(e, file=sys.stderr)


def usage(pipe):
    usage_msg = \
"""jobinfo - collates job information from the 'sstat', 'sacct' and
'squeue' SLURM commands to give a uniform interface for both current
and historical jobs.

Usage:
    jobinfo <job id>

Report problems to hpc@rug.nl"""

    print(usage_msg, file=pipe)


if __name__ == "__main__":
    if "-h" in sys.argv or "--help" in sys.argv:
        usage(sys.stdout)
        sys.exit(0)
    if len(sys.argv) != 2:
        usage(sys.stderr)
        sys.exit(1)
    jobid = sys.argv[1]
    if len(set(jobid) - set("0123456789_.")) > 0:
        print(
            "The argument does not look like a valid job id", file=sys.stderr)
        usage(sys.stderr)
        sys.exit(1)
    main(jobid)
