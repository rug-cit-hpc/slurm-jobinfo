#!/usr/bin/env python3.6
# -*- coding: utf-8 -*-
#
# jobinfo - collect job information from slurm in nicely readable format
#
# Copyright 2015 Anders Halager <aeh@birc.au.dk>
# More functionality added by:
# Bob Dr√∂ge <b.e.droge@rug.nl>
# Egon Rijpkema <e.m.a.rijpkema@rug.nl>
# Fokke Dijkstra <f.dijkstra@rug.nl>
#
# LICENSE: MIT

from collections import namedtuple as NT
import datetime
import json
import math
import os
import pwd
import re
import requests
import subprocess
import sys
import time

# Parameters affecting when hints about job performance will be given.
min_walltime = 180          # Minimum walltime needed before printing job hints
min_memory = 2*1024**3      # Minimum request that will be ignored
ignore_partitions = ['gpu'] # Partitions for which to ignore memory and cpu usage, e.g. GPU partitions
                            # where GPU usage is more important, or where full or partial 
                            # nodes are allocated anyway.

# pynumparser should have been installed to /usr/lib.
# However, if another Python version is loaded as module,
# Python may fail to find pynumparser. In this case we add it
# to the search path manually and try again.
try:
    import pynumparser
except ImportError:
    sys.path.append(f'/usr/lib/python3.{sys.version_info.minor}/site-packages/')
    import pynumparser

def append(l, x):
    if l == '':
        return x
    return ','.join(sorted(set(l.split(',') + [x])))


def keep_first(a, b):
    return a == '' and b or a


def time_max(a, b):
    if 'UNLIMITED' in [a, b]:
        return 'UNLIMITED'
    if a in ['', 'INVALID']:
        return b
    if b in ['', 'INVALID']:
        return a
    return max(a, b)


def time_min(a, b):
    if a in ['', 'INVALID', 'UNLIMITED']:
        return b
    if b in ['', 'INVALID', 'UNLIMITED']:
        return a
    return max(a, b)


def byte_size(s=None):
    if s is None or s == "16?":
        return 0.0
    m = {'K': 10, 'M': 20, 'G': 30, 'T': 40, 'P': 50, 'E': 60}
    scale = 2**m.get(s[-1], 0)
    if scale != 1:
        s = s[:-1]
    return scale * float(s)


def date_str(s=None):
    if s is None or s.strip() == "":
        return "9999-01-01T00:00:00"
    return s


def format_bs(x):
    postfix = ' KMGTPE'
    e = int(math.log(x + 1, 2) / 10)
    return "%.2f%s" % (x / 2**(10 * e), postfix[e])


# Format: [DD-[hh:]]mm:ss
time_parts = re.compile(r'(((?P<days>\d+)-)?(?P<hours>\d\d):)?' +
                        r'(?P<minutes>\d\d):(?P<seconds>\d\d(\.\d+)?)')


def parse_time(t):
    m = time_parts.match(t)
    if m is None:
        return 0.0, 0, 0, 0
    ss = float(m.group('seconds'))
    mm = int(m.group('minutes'))
    hh = int(m.group('hours') or '0')
    dd = int(m.group('days') or '0')
    return ss, mm, hh, dd


def elapsed_to_seconds(elapsed):
    ss, mm, hh, dd = parse_time(elapsed)
    return dd * 24 * 60 * 60 + hh * 60 * 60 + mm * 60 + ss


def f_rss(x, meta):
    return "%s (%s)" % (format_bs(x), meta.MaxRSSNode)


def f_dw(x, meta):
    return "%s (%s)" % (format_bs(x), meta.MaxDiskWriteNode)


def f_dr(x, meta):
    return "%s (%s)" % (format_bs(x), meta.MaxDiskReadNode)


def f_cpu(x, meta):
    total = elapsed_to_seconds(meta.TotalCPU)
    if total == 0:
        return "--"
    xp = elapsed_to_seconds(x)
    return "%5.2f%%" % (xp / total * 100)


def f_mem(x, meta):
    if x.endswith('c'):
        return "%s/core" % (x[:-1])
    elif x.endswith('n'):
        return "%s/node" % (x[:-1])
    else:
        return x


def f_time(x, meta):
    all_times = [meta.timelimit, meta.elapsed, meta.TotalCPU, '-']
    days_len = max(len(y.split('-')[0]) for y in all_times if '-' in y)
    ss, mm, hh, dd = parse_time(x)
    if days_len == 0:
        dd = ""
    else:
        if dd > 0:
            dd = ("%i-" % dd).rjust(days_len)
        else:
            dd = " " * (days_len + 1)
    res = "%s%02i:%02i:%02i" % (dd, hh, mm, ss)
    if res.strip() == "00:00:00":
        return "--"
    return res


def f_cputime(x, meta):
    res = f_time(x, meta)
    if res != "--":
        res += " (efficiency: %5.2f%%)" % efficiency(meta)
    return res


def f_str(x, meta):
    return str(x)


def f_date(x, meta):
    if str(x).lower() == "unknown":
        return "--"
    return str(x)


def f_state(x, meta):
    states = set(x.split(","))
    if len(states) > 1:
        states = states - set(["COMPLETED", ""])
    reason = meta.reason
    if reason != '':
        reason = ' ' + reason
    deps = meta.dependencies
    if deps != '':
        deps = " (%s)" % deps
    return ','.join(states) + reason + deps

def memory_to_bytes(memory_spec, cores_per_node):
   # Convert memory_spec to bytes, ignoring the c or n at the end
   memory_req = byte_size(memory_spec[:-1])

   # If the memory request was per core, multiply by the average number of cores
   # This is the best we can do given the lack of detailed information
   if memory_spec[-1] == 'c':
      memory_req = memory_req*cores_per_node
   return memory_req


def get_cpus_node(nodenames):
    nodename = nodenames.split(',')[-1]
    info = subprocess.Popen(['scontrol', 'show', '-o', 'node', nodename], stdout=subprocess.PIPE)
    num_cpus_match = re.search('cpu=(\d+)', info.stdout.read().decode('UTF-8'))
    if num_cpus_match:
        return int(num_cpus_match.group(1))
    else:
        return 1


def get_hints(meta):
    if meta.end.lower() == 'unknown':
        return

    # Ignore jobs without or too little time
    cputime_secs = elapsed_to_seconds(meta.TotalCPU)
    walltime_secs = elapsed_to_seconds(meta.elapsed)
    # Ignore jobs without or too little time
    if cputime_secs == 0 or walltime_secs < min_walltime:
        return
    if meta.Partition in ignore_partitions:
        return

    hints = []

    # CPU efficiency
    ncpus = meta.ncpus
    eff = 100 * cputime_secs / (ncpus * walltime_secs)
    if (eff < 75):
      if (ncpus == 1):
          hints.append(
              ["The program efficiency is low.",
               "Check the file in- and output pattern of your application."]
          )
      elif (eff <= (100.0 / ncpus)):
          hints.append(
              ["The program efficiency is very low. Your program does not seem to run in",
               "parallel. Please check the program documentation to see how to make the",
               "program run in parallel.",
               "If you can't find information about this, the program will not run in", 
               "parallel! Stop requesting multiple CPU cores if that is the case."]
          )
      else:
          hints.append(
              ["The program efficiency is low. Your program is not using the assigned cores",
               "effectively. Please check if you are using all the cores you requested.",
               "You may also need to check the file in- and output pattern of your program."]
          )
    # Memory efficiency
    max_memory = meta.MaxRSS
    cores_per_node = ncpus / meta.NNodes
    req_memory = memory_to_bytes(meta.ReqMem, cores_per_node)
    cores_max_node = get_cpus_node(meta.MaxRSSNode)
    if req_memory > min_memory*cores_per_node and cores_per_node < cores_max_node:
        if (max_memory/req_memory) < 0.5:
            hints.append(
               ["You requested much more memory than your program used.",
                "Please reduce the requested amount of memory."]
            )

    if len(hints)>0:
        print("Hints and tips      :")
        hint_number = 1
        for hint in hints:
            hint_line = 1
            for line in hint:
                if hint_line == 1:
                    print (" %i) %s" % (hint_number, line))
                else:
                    print ("    %s" % line)
                hint_line = hint_line + 1
            hint_number = hint_number + 1
        print(" *) For more information on these issues see:")
        print("    https://wiki.hpc.rug.nl/peregrine/additional_information/job_hints")


def efficiency(meta):
    cputime_secs = elapsed_to_seconds(meta.TotalCPU)
    walltime_secs = elapsed_to_seconds(meta.elapsed)
    ncpus = meta.ncpus
    if cputime_secs == 0 or walltime_secs == 0 or ncpus == 0:
        eff = 0
    else:
        eff = 100 * elapsed_to_seconds(
            meta.TotalCPU) / (meta.ncpus * elapsed_to_seconds(meta.elapsed))
    return eff


def whoami():
    return pwd.getpwuid(os.getuid()).pw_name


Field = NT('Field', 'name ctor combinator shown prefer_live formatter desc')
FIELDS = [
        Field("JobID",               str,        keep_first,   True,  False, f_str,     "Job ID"),
        Field("JobName",             str,        keep_first,   True,  False, f_str,     "Name"),
        Field("User",                str,        keep_first,   True,  False, f_str,     "User"),
        Field("Partition",           str,        keep_first,   True,  False, f_str,     "Partition"),
        Field("NodeList",            str,        keep_first,   True,  False, f_str,     "Nodes"),
        Field("NNodes",              int,        max,          True,  False, f_str,     "Number of Nodes"),
        Field("ncpus",               int,        max,          True,  False, f_str,     "Cores"),
        Field("State",               str,        append,       True,  False, f_state,   "State"),
        Field("Submit",              str,        keep_first,   True,  False, f_str,     "Submit"),
        Field("start",               date_str,   min,          True,  False, f_date,    "Start"),
        Field("end",                 str,        time_max,     True,  False, f_date,    "End"),
        Field("timelimit",           str,        time_max,     True,  False, f_time,    "Reserved walltime"),
        Field("elapsed",             str,        time_max,     True,  False, f_time,    "Used walltime"),
        Field("TotalCPU",            str,        max,          True,  False, f_cputime, "Used CPU time"),
        Field("UserCPU",             str,        max,          True,  False, f_cpu,     "% User (Computation)"),
        Field("SystemCPU",           str,        max,          True,  False, f_cpu,     "% System (I/O)"),
        Field("ReqMem",              str,        keep_first,   True,  False, f_mem,     "Mem reserved"),
        Field("MaxRSS",              byte_size,  max,          True,  True,  f_rss,     "Max Mem used"),
        Field("MaxDiskWrite",        byte_size,  max,          True,  True,  f_dw,      "Max Disk Write"),
        Field("MaxDiskRead",         byte_size,  max,          True,  True,  f_dr,      "Max Disk Read"),

        Field("MaxRSSNode",          str,        append,       False, True,  None,      ""),
        Field("MaxDiskWriteNode",    str,        append,       False, True,  None,      ""),
        Field("MaxDiskReadNode",     str,        append,       False, True,  None,      ""),
        Field("Comment",             str,        keep_first,   False, False, None,      ""),
        ]

FIELD_NAMES = [f.name for f in FIELDS]
FIELD_NAMES_LIVE = [f.name for f in FIELDS if f.prefer_live]
FIELD_CTORS = [f.ctor for f in FIELDS]
FIELD_COMB = [f.combinator for f in FIELDS]
FORMAT_STR = "--format=%s" % (",".join(FIELD_NAMES))
FORMAT_LIVE_STR = "--format=%s" % (",".join(FIELD_NAMES_LIVE))
Meta = NT('Meta', FIELD_NAMES + ['dependencies', 'reason'])


def combine(xs):
    r = xs[0]
    for x in xs[1:]:
        for i, comb in enumerate(FIELD_COMB):
            r[i] = comb(r[i], x[i])
    return r


def get_values(jobid):
    sacct_cmd = ['sacct', FORMAT_STR, '--parsable', '--noheader', '--delimiter='+u'\u2603', '-j', jobid]
    info = subprocess.Popen(
        map(lambda s: s.encode('utf-8'), sacct_cmd),
        stdout=subprocess.PIPE)
    xs = []
    for line in info.stdout:
        xs.append(
            [(s != "" and ctor(s) or ctor())
             for ctor, s in zip(FIELD_CTORS,
                                line.decode('utf-8').strip().split(u'\u2603'))])
    if len(xs) == 0:
        print("No such job", file=sys.stderr)
        sys.exit(1)
    return xs


def get_live_values(jobid):
    info = subprocess.Popen(
        [
            'sstat', FORMAT_LIVE_STR, '--parsable', '--noheader', '-a', '-j',
            jobid
        ],
        stdout=subprocess.PIPE)
    xs = []
    for line in info.stdout:
        j = 0
        vals = line.decode('utf-8').strip().split('|')
        x = []
        for f in FIELDS:
            if f.prefer_live:
                x.append(f.ctor(vals[j]))
                j += 1
            else:
                x.append(f.ctor())
            xs.append(x)
    return xs


def parse_gpu_string(node_string):
    """
    Parses a string in the format of.
    pg-gpu[1-3] or pg-gpu[2,4,5]
    """
    match = re.search('(.+\[)([0-9]|-|,)+?(?=\])', node_string)
    if match is None:
        return [node_string]

    base, sequence = match.group().split('[')
    parser = pynumparser.NumberSequence(int)
    return ['{}{:02d}'.format(base, i) for i in parser.parse(sequence)]


def get_gpu_usage(node, start, end):
    """
    Calculate the average GPU usage between begin and end stamps.
    Args:
      node (string): The GPU node.
      start (int): start of measurements timestamp.
      end (int): end of measurements timestamp.
    """


    payload = {
        'query':
        'utilization_gpu{{env="peregrine",instance="{}:9101",job="gpu"}}'.
        format(node),
        'start':
        start,
        'end':
        end,
        'step':
        '60s'
    }

    data = requests.get(
        'https://knyft.hpc.rug.nl:9091/api/v1/query_range', params=payload)
    values = []

    for gpu in range(len(json.loads(data.content.decode())['data']['result'])):
        values += json.loads(data.content.decode())['data']['result'][gpu]['values']

    if len(values) > 0:
       average = sum([int(i[1]) for i in values]) / len(values)
    else:
       average = -1
    return average


def get_gpus_usage(nodes, start, end):
    """
    Calculate the average GPU usage between begin and end stamps.
    of a sequence of gpus.
    Args:
      nodes (string): The GPU node(s) in slurm format.
      start (int): start of measurements timestamp.
      end (int): end of measurements timestamp.
    Returns: List: A list of tuples [(<hostname>, <percentage>)]
    """
    return [(gpu, get_gpu_usage(gpu, start, end))
            for gpu in parse_gpu_string(nodes)]


def main(jobid):
    y = combine(get_values(jobid))
    meta = Meta._make(y + ['', ''])
    ys = [y]
    if meta.State == "RUNNING" and (os.getuid() == 0 or meta.User == whoami()):
        # get more info from sstat
        tmp = get_live_values("%s,%s.batch" % (jobid, jobid))
        if len(tmp) != 0:
            ys.append(combine(tmp))
    if meta.State == "PENDING":
        info = subprocess.Popen(
            ['squeue', '--format=%E;%R', '--noheader', '-a', '-j', jobid],
            stdout=subprocess.PIPE)
        deps, reason = info.stdout.readline().decode('utf-8').strip().split(
            ";")
        dependencies = deps
    else:
        dependencies = ""
        reason = ""
    y = combine(ys)
    meta = Meta._make(y + [dependencies, reason])

    for i, (name, parse, comb, show, prefer_live, format,
            desc) in enumerate(FIELDS):
        val = y[i]
        if show:
            print("%-20s: %s" % (desc, format(val, meta)))

    # for  gpu jobs, retreive gpu usage from prometheus.
    if meta.Partition == 'gpu' and meta.start != 'Unknown':
        start = time.mktime(datetime.datetime.strptime(
            meta.start, '%Y-%m-%dT%H:%M:%S').timetuple())
        if meta.end == 'Unknown':
            end = time.time()
        else:
            end = time.mktime(datetime.datetime.strptime(
                meta.end, '%Y-%m-%dT%H:%M:%S').timetuple())
        # prevent the script from crashing if anything  goes wrong.
        # But we do want to read the exception.
        try:
            gpu_usages = get_gpus_usage(meta.NodeList, start, end)
            for gpu, usage in gpu_usages:
                if usage >= 0:
                    print('%-20s: %.1f%% (%s)' % ('Average GPU usage', usage, gpu))
                else:
                    print('%-20s: No GPU metrics available (%s)' % ('Average GPU usage', gpu))
        except Exception as e:
            print('\nGPU usage could not be retrieved.',
                  'The error was:\n')
            print(e, file=sys.stderr)
    get_hints(meta)


def usage(pipe):
    usage_msg = \
"""jobinfo - collates job information from the 'sstat', 'sacct' and
'squeue' SLURM commands to give a uniform interface for both current
and historical jobs.

Usage:
    jobinfo <job id>

Report problems to hpc@rug.nl"""

    print(usage_msg, file=pipe)


if __name__ == "__main__":
    if "-h" in sys.argv or "--help" in sys.argv:
        usage(sys.stdout)
        sys.exit(0)
    if len(sys.argv) != 2:
        usage(sys.stderr)
        sys.exit(1)
    jobid = sys.argv[1]
    if len(set(jobid) - set("0123456789_.")) > 0:
        print(
            "The argument does not look like a valid job id", file=sys.stderr)
        usage(sys.stderr)
        sys.exit(1)
    main(jobid)
